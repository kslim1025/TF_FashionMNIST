{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_MNIST_CNN_VGGNetAndImageAugmentation.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPh9mVVXgXjf2EUIBJ3QiIf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kslim1025/TF_FashionMNIST/blob/master/Fashion_MNIST_CNN_VGGNetAndImageAugmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M7q19z7bXLa"
      },
      "source": [
        "# MNIST 문자열 분석으로 유명한 데이터셋이 패션에 관한 데이터 세트를 만듬 그게 FashionMINIST 데이터셋이다.\n",
        "# 데이터 이미지가 0에서 255까지 값을 가지는 28x28이미지라는 것을 확인가능\n",
        "# 정답이 되는 라벨을 확인하기 위해 print를 붙여서  확인\n",
        "# 외부 데이터를 이용한 정제과정\n",
        "# ctrl+enter를 사용한 런타임가능\n",
        "# !nvidia-smi : 어떤 GPU를 사용하는지 확인가능한 명령어 \n",
        "#\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# 넘파이는 수학과 과학 연산에 특화된 파이썬 모듈로 딥러닝에서도 유용하게 사용된다.\n",
        "\n",
        "import numpy as np;\n",
        "import tensorflow as tf;\n",
        "import pandas as pd;\n",
        "import matplotlib.pyplot as plt;\n",
        "################################################################################\n",
        "!nvidia-smi\n",
        "       \n",
        "#+-----------------------------------------------------------------------------+\n",
        "#| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
        "#|-------------------------------+----------------------+----------------------+\n",
        "#| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "#| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "#|                               |                      |               MIG M. |\n",
        "#|===============================+======================+======================|\n",
        "#|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
        "#| N/A   51C    P0    35W / 250W |   1581MiB / 16280MiB |      0%      Default |\n",
        "#|                               |                      |                 ERR! |\n",
        "#+-------------------------------+----------------------+----------------------+\n",
        "#                                                                               \n",
        "#+-----------------------------------------------------------------------------+\n",
        "#| Processes:                                                                  |\n",
        "#|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "#|        ID   ID                                                   Usage      |\n",
        "#|=============================================================================|\n",
        "#|  No running processes found                                                 |\n",
        "#+-----------------------------------------------------------------------------+\n",
        "\n",
        "################################################################################\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data();\n",
        "\n",
        "print(len(train_X),len(test_X))\n",
        "\n",
        "plt.imshow(train_X[1], cmap='gray')\n",
        "\n",
        "#정규화\n",
        "train_X = train_X / 255.0;\n",
        "train_Y = train_Y / 255.0;\n",
        "\n",
        "print(train_X[0]);\n",
        "\n",
        "#학습 모델을 정의하고 실제 학습하는것이 목표\n",
        "#Flatten이라는 레이어는 다차원레이어를 1차원으로 정렬하는 역할을 합니다\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "                             tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "                             tf.keras.layers.Dense(units=10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "               optimizer = tf.keras.optimizers.Adam(),\n",
        "               loss = 'sparse_categorical_crossentropy',\n",
        "               metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "#분류모델 학습\n",
        "history = model.fit(train_X, train_Y, epochs=25, validation_split=0.25);\n",
        "#분류 모델의 학습 결과 시각화\n",
        "plt.figure(figsize=(12, 4));\n",
        "plt.subplot(1, 2, 1);\n",
        "plt.plot(history.history['loss'], '-b', label='loss');\n",
        "plt.plot(history.history['val_loss'], '--r', label='val_loss');\n",
        "plt.xlabel('Epoch');\n",
        "plt.legend();\n",
        "\n",
        "plt.subplot(1, 2, 2);\n",
        "plt.plot(history.history['accuracy'], '-g', label='accuracy');\n",
        "plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy');\n",
        "plt.xlabel('Epoch');\n",
        "plt.ylim(0.7, 1);\n",
        "plt.legend();\n",
        "\n",
        "plt.show();\n",
        "\n",
        "#분류모델평가\n",
        "model.evaluate(test_X, test_Y);\n",
        "\n",
        "#Conv2D 레이어 생성 코드\n",
        "conv1 = tf.keras.layers.Conv2D(kernel_size=(3,3),strides=(2,2), padding='valid', filters=16);\n",
        "\n",
        "#MaxPool2D 레이어 생성 코드\n",
        "#사각형 안에 최댓값만 남기는 연산을 하게 됩니다.\n",
        "#pool1 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides(2,2));\n",
        "\n",
        "#드롭아웃레이어 생성 코드\n",
        "pool1 = tf.keras.layers.Dropout(rate=0.3);\n",
        "#데이터세트 불러오기 및 정규화\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist;\n",
        "(train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data();\n",
        "\n",
        "train_X = train_X / 255.0;\n",
        "test_X = test_X / 255.0;\n",
        "\n",
        "#reshape 이전, 흑백이기 때문에 1로 지정 RGB이면 3\n",
        "print(train_X.shape, test_X.shape);\n",
        "\n",
        "train_X = train_X.reshape(-1, 28, 28, 1);\n",
        "test_X = test_X.reshape(-1, 28, 28, 1);\n",
        "\n",
        "#reshape 이후\n",
        "print(train_X.shape, test_X.shape);\n",
        "\n",
        "#데이터확인\n",
        "#전체 그래프의 크기를 width=10, height= 10으로 지정합니다\n",
        "\n",
        "plt.figure(figsize=(10, 10));\n",
        "for c in range(16):\n",
        "  # 4행 4열로 지정한 그리드에서 c+1번쨰의칸에 그래프를 그립니다 1~16 번쨰 칸 채우게 합니다\n",
        "  plt.subplot(4, 4, c+1);\n",
        "  plt.imshow(train_X[c].reshape(28, 28), cmap='gray')\n",
        "\n",
        "  plt.show()\n",
        "# 훈련 데이터의 첫 번쨰 ~16 번째 까지의 라벨을 프린트합니다\n",
        "  print(train_Y[:16])\n",
        "\n",
        "#Fashion MNIST 분류를 위한 컨볼류션 신경망 모델 정의\n",
        "  model = tf.keras.Sequential([\n",
        "                               #input_shape=(28, 28, 1) 는 입력 이미지의 높이, 너비, 채널수를 정의한다., 필터수는 16,32,63로 뒤로 갈 수 록 2배씩 늘렸습니다\n",
        "                               tf.keras.layers.Conv2D(input_shape=(28, 28, 1), kernel_size=(3, 3), filters=16),\n",
        "                               tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=32),\n",
        "                               tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=64),\n",
        "                               tf.keras.layers.Flatten(),\n",
        "                               tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "                               tf.keras.layers.Dense(units=10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  model.summary();\n",
        "\n",
        "#Fashion MNIST 분류를 위한 컨볼류션 신경망 모델 학습\n",
        "history = model.fit(train_X, train_Y, epochs=25, validation_split=0.25)\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "plt.subplot(1, 2, 1);\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], 'g--', label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'],'k--', label='val_accracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0.7, 1)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "model.evaluate(test_X, test_Y, verbose=0)\n",
        "\n",
        "#Fashion MNIST 분류를 위한 컨볼류션 신경망 모델 정의 - 풀링 레이어, 드롭아웃 레이어추가\n",
        "\n",
        "model =tf.keras.Sequential([\n",
        "                            tf.keras.layers.Conv2D(input_shape=(28, 28, 1), kernel_size=(3, 3), filters=32),\n",
        "                            tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
        "                            tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64),\n",
        "                            tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
        "                            tf.keras.layers.Conv2D(kernel_size=(3,3), filters=128),\n",
        "                            tf.keras.layers.Flatten(),\n",
        "                            tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "                            tf.keras.layers.Dropout(rate=0.3),\n",
        "                            tf.keras.layers.Dense(units=10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#summary함수로 레이어 구조를 확인해 보면 총 파라미터 수가 400만에 가까운 숫자에 비해 24만 정도로 6% 감소\n",
        "model.summary();\n",
        "\n",
        "#Fashion MNIST 분류를 위한 컨볼류션 신경망 모델 학습 - 풀링레이어, 드롭아웃 레이어 추가\n",
        "history = model.fit(train_X, train_Y, epochs=25, validation_split=0.25)\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], 'g--', label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'],'k--', label='val_accracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0.7, 1)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "model.evaluate(test_X, test_Y, verbose=0)\n",
        "\n",
        "#컨볼루션 신경망에서 퍼포먼스 높이기\n",
        "#그 중 대표적인 두가지 방법 '더 많은 레이어 쌓기', '이미지보강 Image Augmentation'기법\n",
        "\n",
        "#'더 많은 레이어 쌓기'\n",
        "# 딥러닝에서 네트워크 구조를 깊게 쌓는 것이 가능해진 후 딥러닝 발전에 컨볼루션 신경망에서 컨볼루션 레이어가 중첩된 더 깊은 구조가 계속해서 나타 났고 그때마다 이전 구조와 퍼포먼스를 크게 개선했습니다.\n",
        "# LeNet(1998) 5 Layers--> AlexNet(2012) 8 Layers--> VGGNet(2014) 19 Layers --> GoodLeNet(2014) 22Layers --> ReNet(2015) 152Layers\n",
        "\n",
        "# VGGNet의 스타일 구현\n",
        "# VGG는 단순한 구조이면서도 성능이 괜찮기 때문에 지금도 이미지의 특징 추출을 위한 네트워크에서 많이 쓰이고 있습니다\n",
        "# 유명한 Style Transfer논문에서도  VGGNet(VGG-19)를 사용\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Conv2D(input_shape=(28, 28, 1), kernel_size=(3, 3), filters=32, padding='same', activation = 'relu'),\n",
        "                             tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64, padding='same', activation='relu'),\n",
        "                             tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "                             tf.keras.layers.Dropout(rate=0.5),\n",
        "                             tf.keras.layers.Conv2D(kernel_size=(3,3), filters=128, padding='same', activation='relu'),\n",
        "                             tf.keras.layers.Conv2D(kernel_size=(3,3), filters=256, padding='valid', activation='relu'),\n",
        "                             tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "                             tf.keras.layers.Dropout(rate=0.5),\n",
        "                             tf.keras.layers.Flatten(),\n",
        "                             tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "                             tf.keras.layers.Dropout(rate=0.5),\n",
        "                             tf.keras.layers.Dense(units=256, activation='relu'),\n",
        "                             tf.keras.layers.Dropout(rate=0.5),\n",
        "                             tf.keras.layers.Dense(units=10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              tetrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#VGGNet 스타일의 FashionMNiST 분류를 위한 컨볼루션 신경망 모델 학습\n",
        "\n",
        "history = model.fit(train_X, train_Y, epochs=25, validation_split=0.25)\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], 'g-', label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0.7, 1)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "#드디어 val_loss가 잘 증가하지 않는 그래프를 얻었다.\n",
        "#하지만 에포크도 아직 과적합되지 않았기 때문에 늘려도 될 것 같음\n",
        "model.evaluate(test_X, test_Y, verbose=0)\n",
        "# 간단한 네트워크 구조변경만으로 Fashion_MNIST 데이터의 분류 성능을 어느정도 향상 가능\n",
        "\n",
        "#'이미지 보강' 방법 : 훈련 데이터에 없는 이미지를 새롭게 만들어내서 훈련데이터를 보강하는것, 이때 새로운 이미지는 훈련데이터의 이미지를 원본으로 삼고 일정한 변형을 가해서 만들어진다.\n",
        "# 가로,세로,회전, 일부 확대, 기울기, 평행이동 등을 사용한 변경\n",
        "# tf.keras에서는 이러한 이미지 보강 작업을 쉽게 해주는 ImageDataGenerateor가 있다.\n",
        "\n",
        "#Image Augmentation 데이터 표시\n",
        "\n",
        "from tensorflow.keras.prepocessing.image import ImageDataGenerator\n",
        "\n",
        "image_generator = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.10,\n",
        "    shear_range=0.5,\n",
        "    width_shift_range=0.10,\n",
        "    height_shift_range=0.10,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = False)\n",
        "\n",
        "augment_size = 100\n",
        "\n",
        "x_augmented = image_generator.flow(np.title(train_X[0].reshape(28*28),100).reshape(-1, 28, 28, 1), np.zeros(augment_size), batch_size=augment_size, shuffle=False).next()[0]\n",
        "                                   \n",
        "#새롭게 생성된 이미지 표시\n",
        "plt.figure(figsize=(10, 10))\n",
        "for c in range(100):\n",
        "  plt.subplot(10,10,c+1)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(x_augmented[c].reshape(28,28), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "#실제로 신발 이미지가 여러가지 형태로 조금씩 변한것을 확인 가능하다.\n",
        "#flow()함수는 실제로 보강된 이미지를 생성하는데 사용됨\n",
        "\n",
        "#실제로 훈련데이터 이미지를 보강하기 위해 다량의 이미지를 생성하고 학습을 위해 훈련데이터에 추가해보겠습니다\n",
        "image_generator = ImageDataGenerator(\n",
        "    ratation_range=10,\n",
        "    zoom_range=0.10,\n",
        "    shear_range=0.5,\n",
        "    width_shift_range=0.10,\n",
        "    height_shift_range=0.10,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        ")\n",
        "\n",
        "augment_size = 30000\n",
        "\n",
        "randidx = np.random.randint(train_X.shape[0], size=augment_size)\n",
        "x_augmented = train_X[randidx].copy()\n",
        "y_augmented = train_Y[randidx].copy()\n",
        "x_augmented = image_generator.flow(x_augmented, np.zeros(augment_size), batch_size=augment_size, shuffle=False).next()[0];\n",
        "#원래 데이터인 x_train에 이미지 보강된 x_augmented를 추가합니다.\n",
        "\n",
        "train_X = np.concatenate((train_X, x_augmented))\n",
        "train_Y = np.concatenate((train_Y, y_augemted))\n",
        "\n",
        "print(train_X.shape)\n",
        "\n",
        "#훈련 데이터의 50%인 30000개의 이미지를 추가하기 위해  augment_size= 30000으로 설정하고 이미지를 변형할 원본 이미지를 찾기 위해 np.random.randint() 함수를 써서 0 ~ 59.9999 범위의 정수중에서 3만개의 정수를 뽑는다\n",
        "# 이때 정수는 중복될 수 있음\n",
        "# 중복을 원하지 않는 다면 np.random.randint() 대신 np.random.choice()를 사용할것 그리고 replace 인수를 False로 설정\n",
        "\n",
        "#VGGNet style 네트워크 + 이미지 보강 학습\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}